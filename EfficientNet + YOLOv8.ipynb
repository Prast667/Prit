{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prast667/Prit/blob/main/EfficientNet%20%2B%20YOLOv8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxDhgzabwDWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e81b8fd-f058-42f9-d6cd-0ae8fdb80036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.61.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Project-Automated-Kontolodon-10 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 749596/749596 [00:44<00:00, 16849.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Project-Automated-Kontolodon-10 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76938/76938 [00:11<00:00, 6744.88it/s] \n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"5WRtONakONPDAJs712qi\")\n",
        "project = rf.workspace(\"tomsoy\").project(\"project-automated-kontolodon-uxw2m\")\n",
        "version = project.version(10)\n",
        "dataset = version.download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "wUWEEHFYyHOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd64ce58-8e47-464b-c9a0-1dbc11ed70a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 19 20:52:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics tensorflow opencv-python scikit-learn\n"
      ],
      "metadata": {
        "id": "Qj3E9lDwyOcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e9c2ba-cc7e-40ee-9974-7800829c18d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.240)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train YOLOv8 Model for Bounding Box Generation\n"
      ],
      "metadata": {
        "id": "7R9TodHrL45u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model_yolo = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "model_yolo.train(\n",
        "    data=\"/content/Project-Automated-Kontolodon-10/data.yaml\",\n",
        "    epochs=20,\n",
        "    imgsz=640,\n",
        "    batch=26\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDKGcP8TyQRp",
        "outputId": "16650fbf-73db-46cd-da7a-9f0f51d12ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 378.2MB/s 0.0s\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=26, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Project-Automated-Kontolodon-10/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 13.6MB/s 0.1s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 325.2MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 803.1Â±332.9 MB/s, size: 19.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Project-Automated-Kontolodon-10/train/labels... 33675 images, 9 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33675/33675 2.5Kit/s 13.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/Project-Automated-Kontolodon-10/train/images/metal803_jpeg.rf.6752d772b52ebd69cd11f1313d4de791.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/Project-Automated-Kontolodon-10/train/images/metal803_jpeg.rf.893650d6c1f42eb6e11d2d26077b8ac1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/Project-Automated-Kontolodon-10/train/images/metal803_jpeg.rf.fc7cf388b1da5def96011d309b097205.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Project-Automated-Kontolodon-10/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 1170, len(boxes) = 73032. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 453.6Â±491.4 MB/s, size: 17.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Project-Automated-Kontolodon-10/valid/labels... 2366 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2366/2366 1.0Kit/s 2.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Project-Automated-Kontolodon-10/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 101, len(boxes) = 4869. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00040625000000000004), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      4.72G      1.219      2.307       1.57         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.3it/s 9:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.1it/s 22.2s\n",
            "                   all       2366       4869      0.567      0.574      0.565      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      5.17G      1.191      1.769      1.548         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.5it/s 8:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.5it/s 18.4s\n",
            "                   all       2366       4869      0.548      0.538       0.52      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      5.18G      1.273      1.774      1.613         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.5it/s 8:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.4it/s 18.9s\n",
            "                   all       2366       4869      0.519      0.494      0.484       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20       5.2G      1.283      1.743      1.623         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.5it/s 8:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.6it/s 17.6s\n",
            "                   all       2366       4869      0.615      0.531      0.571      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      5.21G      1.224      1.614      1.583         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.6it/s 8:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.5it/s 18.2s\n",
            "                   all       2366       4869      0.686      0.637      0.681      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      5.22G      1.186      1.506      1.553         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.6it/s 8:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.6it/s 17.5s\n",
            "                   all       2366       4869      0.698      0.636      0.693      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      5.23G      1.164      1.449      1.539         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.6it/s 8:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.7it/s 17.0s\n",
            "                   all       2366       4869      0.721      0.667      0.729      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      5.24G      1.148      1.406      1.525         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.6it/s 8:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.6it/s 17.8s\n",
            "                   all       2366       4869      0.731      0.697      0.755      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      5.25G      1.119      1.346      1.505         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.6it/s 8:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.6it/s 17.9s\n",
            "                   all       2366       4869      0.745      0.713       0.77      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      5.27G      1.105      1.298      1.493         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.6it/s 8:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.5it/s 18.3s\n",
            "                   all       2366       4869      0.766      0.738      0.799      0.551\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      5.28G      1.137      1.219      1.622         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.2it/s 9:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.0it/s 22.7s\n",
            "                   all       2366       4869      0.774      0.733      0.802      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      5.29G      1.111       1.15      1.596         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.2it/s 9:43\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.0it/s 22.8s\n",
            "                   all       2366       4869      0.794      0.745      0.813      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20       5.3G      1.088      1.093      1.577          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.3it/s 9:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.5it/s 18.1s\n",
            "                   all       2366       4869      0.793      0.753      0.816      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      5.31G      1.068       1.05       1.56         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.2it/s 9:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.1it/s 21.4s\n",
            "                   all       2366       4869      0.791      0.756      0.825       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      5.32G      1.056      1.009      1.544         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.2it/s 9:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.2it/s 21.4s\n",
            "                   all       2366       4869      0.795      0.783      0.834      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      5.33G       1.04     0.9681      1.532         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.2it/s 9:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.5it/s 18.2s\n",
            "                   all       2366       4869      0.791      0.785      0.837      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      5.34G      1.018     0.9274       1.51         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.3it/s 9:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.7it/s 17.1s\n",
            "                   all       2366       4869      0.811      0.779      0.839      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      5.36G      1.003     0.8927      1.497          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.7it/s 7:60\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.7it/s 17.1s\n",
            "                   all       2366       4869      0.807      0.782       0.84      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      5.37G     0.9863     0.8596      1.485          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.7it/s 7:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.7it/s 16.9s\n",
            "                   all       2366       4869      0.805      0.783      0.841      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      5.38G     0.9695     0.8287      1.469         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1296/1296 2.7it/s 7:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.6it/s 17.6s\n",
            "                   all       2366       4869      0.817      0.785      0.843      0.617\n",
            "\n",
            "20 epochs completed in 3.037 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 46/46 2.3it/s 20.1s\n",
            "                   all       2366       4869      0.817      0.784      0.843      0.617\n",
            "             Anorganik        569        799      0.881      0.851      0.904      0.669\n",
            "                    B3        597       1002       0.75       0.82      0.838      0.651\n",
            "                 Logam        543        800      0.789      0.876      0.892      0.749\n",
            "               Organik        657       2268      0.847      0.587      0.738      0.398\n",
            "Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 3])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f7a7e8571a0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.018126,   0.0090628,           0],\n",
              "       [          1,           1,           1, ...,   0.0049509,   0.0024755,           0],\n",
              "       [          1,           1,           1, ...,    0.017039,   0.0085197,           0],\n",
              "       [          1,           1,           1, ...,   0.0019979,  0.00099893,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.22132,     0.22132,     0.29509, ...,           0,           0,           0],\n",
              "       [    0.18307,     0.18307,     0.23855, ...,           0,           0,           0],\n",
              "       [    0.17459,     0.17459,     0.24345, ...,           0,           0,           0],\n",
              "       [   0.080912,    0.080912,     0.10758, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.12464,     0.12464,     0.17374, ...,           1,           1,           1],\n",
              "       [    0.10119,     0.10119,     0.13632, ...,           1,           1,           1],\n",
              "       [   0.095751,    0.095751,     0.13884, ...,           1,           1,           1],\n",
              "       [    0.04224,     0.04224,    0.057018, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98623,     0.98623,     0.97872, ...,           0,           0,           0],\n",
              "       [    0.95908,     0.95908,     0.95409, ...,           0,           0,           0],\n",
              "       [    0.98875,     0.98875,      0.9875, ...,           0,           0,           0],\n",
              "       [    0.95767,     0.95767,     0.95018, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.6167864039589124)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.66939,     0.65101,     0.74869,     0.39806])\n",
              "names: {0: 'Anorganik', 1: 'B3', 2: 'Logam', 3: 'Organik'}\n",
              "nt_per_class: array([ 799, 1002,  800, 2268])\n",
              "nt_per_image: array([569, 597, 543, 657])\n",
              "results_dict: {'metrics/precision(B)': 0.8168886403813085, 'metrics/recall(B)': 0.7837535776120688, 'metrics/mAP50(B)': 0.8430176386461238, 'metrics/mAP50-95(B)': 0.6167864039589124, 'fitness': 0.6167864039589124}\n",
              "save_dir: PosixPath('/content/runs/detect/train')\n",
              "speed: {'preprocess': 0.22409318638998824, 'inference': 2.128268222315035, 'loss': 0.00022240405800809024, 'postprocess': 1.951118158495103}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate YOLOv8 Detection Performance\n"
      ],
      "metadata": {
        "id": "f3dyVAxzL-tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"runs/detect/train/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "NnjDrMii6Li3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = \"/content/Project-Automated-Kontolodon-10\"\n",
        "\n",
        "CLASS_NAMES = ['Organik', 'Anorganik', 'Metal', 'B3']\n"
      ],
      "metadata": {
        "id": "3PGDSXiCZ5U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Object-Level Waste Images via YOLO-Based Cropping\n"
      ],
      "metadata": {
        "id": "iHgSbpgaMD8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "DATASET_ROOT = \"/content/Project-Automated-Kontolodon-10\"\n",
        "CLASS_NAMES = ['Organik', 'Anorganik', 'Metal', 'B3']\n",
        "\n",
        "def crop_dataset(split):\n",
        "    img_dir = f\"{DATASET_ROOT}/{split}/images\"\n",
        "    lbl_dir = f\"{DATASET_ROOT}/{split}/labels\"\n",
        "    out_dir = f\"/content/dataset_cls/{split}\"\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for c in CLASS_NAMES:\n",
        "        os.makedirs(os.path.join(out_dir, c), exist_ok=True)\n",
        "\n",
        "    for img_name in os.listdir(img_dir):\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        lbl_path = os.path.join(lbl_dir, img_name.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        if not os.path.exists(lbl_path):\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        with open(lbl_path) as f:\n",
        "            for i, line in enumerate(f):\n",
        "                values = list(map(float, line.split()))\n",
        "                cls, x, y, bw, bh = values[:5]\n",
        "\n",
        "                x1 = int((x - bw/2) * w)\n",
        "                y1 = int((y - bh/2) * h)\n",
        "                x2 = int((x + bw/2) * w)\n",
        "                y2 = int((y + bh/2) * h)\n",
        "\n",
        "                crop = img[y1:y2, x1:x2]\n",
        "                if crop.size == 0:\n",
        "                    continue\n",
        "\n",
        "                cls_name = CLASS_NAMES[int(cls)]\n",
        "                save_path = f\"{out_dir}/{cls_name}/{img_name}_{i}.jpg\"\n",
        "                cv2.imwrite(save_path, crop)\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    crop_dataset(split)\n"
      ],
      "metadata": {
        "id": "Ys-no42oZ6uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Object-Level Dataset for Classification\n"
      ],
      "metadata": {
        "id": "-3wrWI1fMIQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "BASE_PATH = \"/content/dataset_cls\"\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{BASE_PATH}/train\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{BASE_PATH}/valid\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{BASE_PATH}/test\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "SnpUF2m265T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690907d7-e684-4277-c13b-970c6484f724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 72720 files belonging to 4 classes.\n",
            "Found 4853 files belonging to 4 classes.\n",
            "Found 5283 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "R8kVbuAP67oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Object-Level Dataset for Classification\n"
      ],
      "metadata": {
        "id": "-OeB-J5nMMds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "base_model = EfficientNetB0(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n"
      ],
      "metadata": {
        "id": "pqARPQUQ68ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55953265-98be-4bef-b05a-b7eead1a723a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "cKak9JuN7CAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "MNTNhtX77ENd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/efficientnet_ckpt.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "CariwLjYbZHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train EfficientNet-B0 (Frozen Backbone)\n"
      ],
      "metadata": {
        "id": "A_wI9m0PMSd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "id": "S_sRbIBq7GMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca48f206-2622-4ba2-a659-69a6ea7c0e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6707 - loss: 0.8364\n",
            "Epoch 1: val_loss improved from inf to 0.41937, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 59ms/step - accuracy: 0.6707 - loss: 0.8363 - val_accuracy: 0.8628 - val_loss: 0.4194\n",
            "Epoch 2/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8368 - loss: 0.4641\n",
            "Epoch 2: val_loss improved from 0.41937 to 0.36140, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 39ms/step - accuracy: 0.8368 - loss: 0.4641 - val_accuracy: 0.8786 - val_loss: 0.3614\n",
            "Epoch 3/20\n",
            "\u001b[1m2271/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8551 - loss: 0.4156\n",
            "Epoch 3: val_loss improved from 0.36140 to 0.33860, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 38ms/step - accuracy: 0.8551 - loss: 0.4156 - val_accuracy: 0.8850 - val_loss: 0.3386\n",
            "Epoch 4/20\n",
            "\u001b[1m2271/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8639 - loss: 0.3929\n",
            "Epoch 4: val_loss improved from 0.33860 to 0.32456, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 38ms/step - accuracy: 0.8639 - loss: 0.3929 - val_accuracy: 0.8906 - val_loss: 0.3246\n",
            "Epoch 5/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8683 - loss: 0.3802\n",
            "Epoch 5: val_loss improved from 0.32456 to 0.31611, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8683 - loss: 0.3802 - val_accuracy: 0.8943 - val_loss: 0.3161\n",
            "Epoch 6/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8710 - loss: 0.3710\n",
            "Epoch 6: val_loss improved from 0.31611 to 0.30967, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 38ms/step - accuracy: 0.8710 - loss: 0.3710 - val_accuracy: 0.8955 - val_loss: 0.3097\n",
            "Epoch 7/20\n",
            "\u001b[1m2271/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8743 - loss: 0.3625\n",
            "Epoch 7: val_loss improved from 0.30967 to 0.30381, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 40ms/step - accuracy: 0.8744 - loss: 0.3625 - val_accuracy: 0.8972 - val_loss: 0.3038\n",
            "Epoch 8/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8748 - loss: 0.3623\n",
            "Epoch 8: val_loss improved from 0.30381 to 0.30097, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 38ms/step - accuracy: 0.8748 - loss: 0.3623 - val_accuracy: 0.8986 - val_loss: 0.3010\n",
            "Epoch 9/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8771 - loss: 0.3552\n",
            "Epoch 9: val_loss improved from 0.30097 to 0.29836, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 38ms/step - accuracy: 0.8771 - loss: 0.3552 - val_accuracy: 0.8996 - val_loss: 0.2984\n",
            "Epoch 10/20\n",
            "\u001b[1m2271/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8760 - loss: 0.3504\n",
            "Epoch 10: val_loss improved from 0.29836 to 0.29376, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8760 - loss: 0.3504 - val_accuracy: 0.9023 - val_loss: 0.2938\n",
            "Epoch 11/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8780 - loss: 0.3483\n",
            "Epoch 11: val_loss improved from 0.29376 to 0.29242, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8780 - loss: 0.3483 - val_accuracy: 0.9025 - val_loss: 0.2924\n",
            "Epoch 12/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8765 - loss: 0.3492\n",
            "Epoch 12: val_loss improved from 0.29242 to 0.29150, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 38ms/step - accuracy: 0.8765 - loss: 0.3492 - val_accuracy: 0.9023 - val_loss: 0.2915\n",
            "Epoch 13/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8792 - loss: 0.3437\n",
            "Epoch 13: val_loss improved from 0.29150 to 0.28949, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 40ms/step - accuracy: 0.8792 - loss: 0.3437 - val_accuracy: 0.9021 - val_loss: 0.2895\n",
            "Epoch 14/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8786 - loss: 0.3438\n",
            "Epoch 14: val_loss improved from 0.28949 to 0.28759, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 38ms/step - accuracy: 0.8786 - loss: 0.3438 - val_accuracy: 0.9023 - val_loss: 0.2876\n",
            "Epoch 15/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8779 - loss: 0.3423\n",
            "Epoch 15: val_loss improved from 0.28759 to 0.28728, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8779 - loss: 0.3423 - val_accuracy: 0.9042 - val_loss: 0.2873\n",
            "Epoch 16/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8787 - loss: 0.3390\n",
            "Epoch 16: val_loss improved from 0.28728 to 0.28676, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 38ms/step - accuracy: 0.8787 - loss: 0.3390 - val_accuracy: 0.9046 - val_loss: 0.2868\n",
            "Epoch 17/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8797 - loss: 0.3400\n",
            "Epoch 17: val_loss improved from 0.28676 to 0.28609, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 38ms/step - accuracy: 0.8797 - loss: 0.3400 - val_accuracy: 0.9056 - val_loss: 0.2861\n",
            "Epoch 18/20\n",
            "\u001b[1m2272/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8799 - loss: 0.3394\n",
            "Epoch 18: val_loss improved from 0.28609 to 0.28178, saving model to /content/drive/MyDrive/efficientnet_ckpt.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 40ms/step - accuracy: 0.8799 - loss: 0.3394 - val_accuracy: 0.9054 - val_loss: 0.2818\n",
            "Epoch 19/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8797 - loss: 0.3396\n",
            "Epoch 19: val_loss did not improve from 0.28178\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 46ms/step - accuracy: 0.8797 - loss: 0.3396 - val_accuracy: 0.9048 - val_loss: 0.2831\n",
            "Epoch 20/20\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8808 - loss: 0.3385\n",
            "Epoch 20: val_loss did not improve from 0.28178\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 46ms/step - accuracy: 0.8808 - loss: 0.3385 - val_accuracy: 0.9052 - val_loss: 0.2838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tune EfficientNet-B0"
      ],
      "metadata": {
        "id": "wXuJI5arMXDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10)\n"
      ],
      "metadata": {
        "id": "DGYOIzXp7JgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e512b2-4682-40dc-ac60-10c6b8d45123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 171ms/step - accuracy: 0.7533 - loss: 0.6526 - val_accuracy: 0.9069 - val_loss: 0.2820\n",
            "Epoch 2/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 136ms/step - accuracy: 0.8703 - loss: 0.3682 - val_accuracy: 0.9238 - val_loss: 0.2359\n",
            "Epoch 3/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 140ms/step - accuracy: 0.8974 - loss: 0.2919 - val_accuracy: 0.9322 - val_loss: 0.2146\n",
            "Epoch 4/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 139ms/step - accuracy: 0.9147 - loss: 0.2399 - val_accuracy: 0.9382 - val_loss: 0.1999\n",
            "Epoch 5/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 138ms/step - accuracy: 0.9295 - loss: 0.2052 - val_accuracy: 0.9409 - val_loss: 0.1891\n",
            "Epoch 6/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 141ms/step - accuracy: 0.9373 - loss: 0.1805 - val_accuracy: 0.9446 - val_loss: 0.1801\n",
            "Epoch 7/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 141ms/step - accuracy: 0.9456 - loss: 0.1575 - val_accuracy: 0.9440 - val_loss: 0.1752\n",
            "Epoch 8/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 142ms/step - accuracy: 0.9536 - loss: 0.1341 - val_accuracy: 0.9481 - val_loss: 0.1727\n",
            "Epoch 9/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 141ms/step - accuracy: 0.9580 - loss: 0.1220 - val_accuracy: 0.9481 - val_loss: 0.1724\n",
            "Epoch 10/10\n",
            "\u001b[1m2273/2273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 131ms/step - accuracy: 0.9624 - loss: 0.1094 - val_accuracy: 0.9491 - val_loss: 0.1695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f789ce74c80>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "sOabKsJc7QRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Classification Performance\n"
      ],
      "metadata": {
        "id": "RvmgVp6NMi2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "y_pred = np.argmax(model.predict(test_ds), axis=1)\n"
      ],
      "metadata": {
        "id": "28eRV6Te7RLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc02fb08-5fc5-488e-d100-764d0f85871e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m166/166\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "eorSxwFS7TNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0424db-b788-4d4c-dfc1-fb8f621df6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       799\n",
            "           1       0.96      0.97      0.96      1944\n",
            "           2       0.96      0.94      0.95      1720\n",
            "           3       0.96      0.94      0.95       820\n",
            "\n",
            "    accuracy                           0.95      5283\n",
            "   macro avg       0.95      0.95      0.95      5283\n",
            "weighted avg       0.95      0.95      0.95      5283\n",
            "\n",
            "[[ 768    9   16    6]\n",
            " [   6 1882   41   15]\n",
            " [  33   56 1623    8]\n",
            " [  14   16   19  771]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_true = np.concatenate([y.numpy() for x, y in test_ds], axis=0)\n",
        "y_pred = np.argmax(model.predict(test_ds), axis=1)\n"
      ],
      "metadata": {
        "id": "MCF9IkgC7VG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70248063-0af9-4d3e-bf8e-c551be82646c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m166/166\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "SG714YE87tdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7462c508-8268-4c5a-9fb8-0c822b89328b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 768    9   16    6]\n",
            " [   6 1882   41   15]\n",
            " [  33   56 1623    8]\n",
            " [  14   16   19  771]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=CLASS_NAMES,\n",
        "    yticklabels=CLASS_NAMES,\n",
        "    cbar=False\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix of EfficientNet-based Waste Classification\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vzzRYMmQ7v0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "0bba0ade-29b1-4606-e2a0-3360535ee770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm_norm,\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cmap='Blues',\n",
        "    xticklabels=CLASS_NAMES,\n",
        "    yticklabels=CLASS_NAMES,\n",
        "    cbar=False\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Normalized Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "joRiXedr7y44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "34a461f9-2769-4a71-c917-7b8006eb457a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_class_samples(base_dir):\n",
        "    counts = {}\n",
        "    for cls in CLASS_NAMES:\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        counts[cls] = len(os.listdir(cls_path))\n",
        "    return counts\n",
        "\n",
        "train_counts = count_class_samples(\"dataset_cls/train\")\n",
        "val_counts   = count_class_samples(\"dataset_cls/valid\")\n",
        "test_counts  = count_class_samples(\"dataset_cls/test\")\n",
        "\n",
        "print(\"Train:\", train_counts)\n",
        "print(\"Validation:\", val_counts)\n",
        "print(\"Test:\", test_counts)\n"
      ],
      "metadata": {
        "id": "bjkZBZyn710Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8128ac-2f12-45f9-d7df-74999fe50453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: {'Organik': 11007, 'Anorganik': 16542, 'Metal': 17572, 'B3': 27599}\n",
            "Validation: {'Organik': 799, 'Anorganik': 986, 'Metal': 800, 'B3': 2268}\n",
            "Test: {'Organik': 820, 'Anorganik': 799, 'Metal': 1720, 'B3': 1944}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=CLASS_NAMES,\n",
        "    digits=4\n",
        "))\n"
      ],
      "metadata": {
        "id": "NHLLAiYV76tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745557c4-eea4-4021-896d-c8997a9b24d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Organik     0.9354    0.9612    0.9481       799\n",
            "   Anorganik     0.9587    0.9681    0.9634      1944\n",
            "       Metal     0.9553    0.9436    0.9494      1720\n",
            "          B3     0.9637    0.9402    0.9519       820\n",
            "\n",
            "    accuracy                         0.9548      5283\n",
            "   macro avg     0.9533    0.9533    0.9532      5283\n",
            "weighted avg     0.9549    0.9548    0.9547      5283\n",
            "\n"
          ]
        }
      ]
    }
  ]
}